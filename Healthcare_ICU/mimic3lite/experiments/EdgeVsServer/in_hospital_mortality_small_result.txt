Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 2453.951358795166
load data time: 0.2276897430419922
process data time: 262.2854709625244

32/32 [==============================] - 1s 20ms/step
The inference time is  655.9402942657471
save time is: 0.6515979766845703
total time is  3375.577211380005
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 5839.730024337769
load data time: 0.537872314453125
process data time: 227.53477096557617

32/32 [==============================] - 0s 14ms/step
The inference time is  465.9721851348877
save time is: 0.6418228149414062
total time is  6539.499044418335
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 3658.005714416504
load data time: 0.6799697875976562
process data time: 296.3113784790039

32/32 [==============================] - 1s 26ms/step
The inference time is  823.9216804504395
save time is: 0.47016143798828125
total time is  4782.930135726929
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 5248.671293258667
load data time: 0.35953521728515625
process data time: 271.76570892333984

32/32 [==============================] - 1s 19ms/step
The inference time is  602.4460792541504
save time is: 0.5810260772705078
total time is  6127.33006477356
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 5402.521133422852
load data time: 0.5049705505371094
process data time: 249.5112419128418

32/32 [==============================] - 1s 17ms/step
The inference time is  550.3997802734375
save time is: 0.41556358337402344
total time is  6207.0112228393555
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 7458.288669586182
load data time: 0.2663135528564453
process data time: 181.21337890625

32/32 [==============================] - 1s 18ms/step
The inference time is  586.0154628753662
save time is: 0.6463527679443359
total time is  8228.867292404175
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 3720.576763153076
load data time: 0.3218650817871094
process data time: 300.6772994995117

32/32 [==============================] - 1s 18ms/step
The inference time is  574.2847919464111
save time is: 0.5841255187988281
total time is  4599.8992919921875
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 5898.231029510498
load data time: 0.4029273986816406
process data time: 315.54174423217773

32/32 [==============================] - 1s 42ms/step
The inference time is  1335.4878425598145
save time is: 1.271963119506836
total time is  7554.420709609985
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 5282.767534255981
load data time: 0.514984130859375
process data time: 297.4390983581543

32/32 [==============================] - 0s 14ms/step
The inference time is  464.1733169555664
save time is: 0.5548000335693359
total time is  6048.18320274353
Namespace(batch_norm=False, batch_size=32, beta_1=0.9, data='/mnt/sdc/Edge/ICU_Patient_Monitor/mimic3lite/mimic3models/in_hospital_mortality/../../data/in-hospital-mortality/', datasize='small', depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.28048032904211445.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/in_hospital_mortality', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)
==> using model mimic3models/keras_models/lstm.py
==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'datasize', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])
==> model.final_name: k_lstm.n16.d0.3.dep2.bs32.ts1.0
==> compiling the model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
X (InputLayer)               (None, None, 76)          0         
_________________________________________________________________
masking_1 (Masking)          (None, None, 76)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 16)          5440      
_________________________________________________________________
lstm_2 (LSTM)                (None, 16)                2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 7,569
Trainable params: 7,569
Non-trainable params: 0
_________________________________________________________________
load model time: 8773.231983184814
load data time: 0.26154518127441406
process data time: 291.23640060424805

32/32 [==============================] - 1s 25ms/step
The inference time is  793.0557727813721
save time is: 0.400543212890625
total time is  9861.77682876587
